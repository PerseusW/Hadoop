# Homework 2

### 为什么需要并行计算？

​       贯穿整个计算机技术发展的核心目标是提高计算性能。实现这个目标的主要手段有，提高处理器字长、提高集成度、流水线等微体系结构技术、提高处理器频率。然而，这些手段都开始遇到瓶颈，VLSI集成度不可能无限制提高、处理器的指令集并行度提升接近极限、处理器速度和存储器速度差异越来越大、功耗和散热大幅增加超过芯片承受能力，这一系列的瓶颈导致单核处理器性能提升接近极限。因此，为了继续提高计算性能，向多核并行计算发展成为必然趋势。

### 并行计算按照系统类型划分，可以分为哪几种？简述每一种系统类型的特点。

​       多核/众核并行计算系统MC：是芯片级的并行，高耦合度，低扩展性。

​       对称多处理系统SMP：多个相同类型处理器通过总线连接并共享存储器。

​       大规模并行处理MPP：专用内联网连接一组处理器形成的一个计算系统。

​       集群Cluster：网络连接的一组商用计算机构成的计算系统。

​       网格Grid：用网络连接远距离分布的一组异构计算机构成的计算系统。

### 并行计算按照并行程序设计方法分类，可以分为哪几种？简述每一种方法的特点。

​       共享内存变量方式：通常被称为多线程并行程序设计；可能引起数据不一致性，导致数据和资源访问冲突，需要引入同步控制机制。

​       消息传递方式：可以狭隘地理解为多进程程序设计；分发数据实现并行计算、随后收集计算结果，需要在各个计算节点或者计算任务间进行数据通信。

​       MapReduce并行程序设计方式：Google提出的并行程序设计模型，是当时最易于使用的并行程序设计方法，广泛使用于搜索引擎等大规模数据并行处理。

​       其他新型并行计算和编程方式：实时流式计算、迭代计算、图计算以及基于内存的计算等。

### MPI提供哪几种通信方式/接口？

​       MPI_Init(argc, argv)：初始化MPI，开始MPI并行计算程序体

​       MPI_Finalize：终止MPI并行计算

​       MPI_Comm_Size(comm,size)：确定指定范围内处理器/进程数目

​       MPI_Comm_Rank(comm,rank)：确定一个处理器/进程的标识号

​       MPI_Send(buf,count,datatype,dest,tag,comm)：发送一个消息

​       MPI_Recv(buf,count,datatype,source,tag,comm,status)：接收消息

​       MPI_ISend(buf,count,datatype,dest,tag,comm,request)：异步发送一个消息

​       MPI_IRecv(buf,count,datatype,source,tag,comm,status,request)：异步接收消息

​       MPI_Wait(request,status)：等待非阻塞数据传输完成

​       MPI_Test(request,flag,status)：检查是否异步数据传输确实完成

 

 

### 尝试在单机上安装并运行MPICH-3.3.1，并运行讲义P61页的简单示例。（运行结果截图）

<left>
    <img src="images\H2-01.png"
</left>

